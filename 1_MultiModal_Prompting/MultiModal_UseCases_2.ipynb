{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Multimodal Use Case",
   "id": "2c367d6f-7ef4-4db2-8bea-17781a3a351e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "fbade2c6-5ada-41fe-808b-ee74e6adcc8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "## Load helper functions\n",
    "from utils import load_env\n",
    "load_env()\n",
    "from utils import llama32\n",
    "from utils import encode_image\n",
    "from utils import llama32pi"
   ],
   "id": "c1f03559-9c4b-45b6-ae20-52dffa25f380"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# OCR (Optical Character Recognition) with Llama 3",
   "id": "cb846a92a66ecd06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import disp_image\n",
    "for i in range(1, 4):\n",
    "  disp_image(f\"images/receipt-{i}.jpg\")"
   ],
   "id": "ad0c9596-904f-4d0d-abb2-2617a5caf0a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = \"What's the total charge in the receipt?\"\n",
    "results = \"\"\n",
    "for i in range(1, 4):\n",
    "    base64_image = encode_image(f\"images/receipt-{i}.jpg\")\n",
    "    res = llama32pi(question, f\"data:image/jpeg;base64,{base64_image}\")\n",
    "    results = results + f\"{res}\\n\"\n",
    "print(results) #results saves the charge in each receipt"
   ],
   "id": "ee5d860c-4a2e-4402-8ec8-402c9b820e05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": f\"\"\"What's the total charge of all the receipts below?\n",
    "{results}\"\"\"\n",
    "  }\n",
    "]"
   ],
   "id": "2ff3983a-d2e8-4272-a21c-ffb63d3a7d86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "response = llama32(messages)\n",
    "print(response)"
   ],
   "id": "c66669f6-ea61-4db5-8369-8b677ed7637f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Handling multiple images",
   "id": "f6bb4d62-6bc5-464e-ae04-247530445360"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import merge_images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "merged_image = merge_images(\"images/receipt-1.jpg\",\n",
    "                            \"images/receipt-2.jpg\",\n",
    "                            \"images/receipt-3.jpg\")\n",
    "plt.imshow(merged_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ],
   "id": "21c3b1b2-4628-4830-8802-175c357ced12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import resize_image\n",
    "resized_img = resize_image(merged_image)"
   ],
   "id": "b19de0e1-b131-4ce4-a3af-1ca7c7c09daa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "base64_image = encode_image(\"images/resized_image.jpg\")\n",
    "question = \"What's the total charge of all the receipts below?\"\n",
    "result = llama32pi(question,\n",
    "                      f\"data:image/jpeg;base64,{base64_image}\")\n",
    "print(result)"
   ],
   "id": "5ff3a5ac-ffbb-4f6d-9b33-d1b2651c6472"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model can interpreting nutrition labels and offer recommendations. Also it can interpret complex diagrams",
   "id": "719c5c75-ddcd-4d08-a7db-d54e748c3a7f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Interpretation of graphics and code generation",
   "id": "1ea78434-cfa6-4747-928c-8738078d4d48"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "disp_image(\"images/llama32mm.png\")",
   "id": "14900655-de22-4b29-97c9-45b6ff840485"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = (\"I see this diagram in the Llama 3 paper. \"\n",
    "            \"Summarize the flow in text and then return a \"\n",
    "            \"python script that implements the flow.\")\n",
    "base64_image = encode_image(\"images/llama32mm.png\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ],
   "id": "456c27b2-b80a-4a12-bdea-1485566d593b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Converting input to another format",
   "id": "6cf566eb-2ec3-493b-a326-458d574d7999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "disp_image(\"images/llama31speed.png\")",
   "id": "065bf3b0-2cfd-4380-b927-f8cd4c755a22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = \"Convert the chart to an HTML table.\"\n",
    "base64_image = encode_image(\"images/llama31speed.png\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ],
   "id": "e638704f-6c5b-4fc5-8436-3e6253950a6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from IPython.display import HTML\n",
    "#this is the previous response\n",
    "minified_html_table = \"<table><thead><tr><th>Model</th><th>Output Tokens per Second</th></tr></thead><tbody><tr><td>Llama 2 1.5B</td><td>217</td></tr><tr><td>Google's PaLM 2 540B</td><td>214</td></tr><tr><td>Google's PaLM 2 540B</td><td>163</td></tr><tr><td>Meta's LLaMA 2 70B</td><td>133</td></tr><tr><td>Meta's LLaMA 2 70B</td><td>129</td></tr><tr><td>Google's T5 3.5B</td><td>123</td></tr><tr><td>OPT-6B</td><td>111</td></tr><tr><td>OPT-6B</td><td>75</td></tr><tr><td>ChatGPT-3.5</td><td>64</td></tr><tr><td>Google's T5 3.5B</td><td>62</td></tr><tr><td>Google's T5 3.5B</td><td>61</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>68</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>38</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>38</td></tr><tr><td>Meta's LLaMA 2 7B</td><td>25</td></tr></tbody></table>\"\n",
    "HTML(minified_html_table)"
   ],
   "id": "8b062ad4-d93c-4a9a-8977-6591c30b6492"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Following up a question in multimodal context (images and text)",
   "id": "2c831694-ea1f-46d5-8c82-a06f6860231b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "disp_image(\"images/fridge-3.jpg\")",
   "id": "98d71078-863f-45cc-bc12-6e3dda7ee391"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = (\"What's in the fridge? What kind of food can be made? Give \"\n",
    "            \"me 2 examples, based on only the ingredients in the fridge.\")\n",
    "base64_image = encode_image(\"images/fridge-3.jpg\")\n",
    "result = llama32pi(question, f\"data:image/jpg;base64,{base64_image}\")\n",
    "print(result)"
   ],
   "id": "cbf3e606-b579-4a29-9f6f-d0308b5e39ab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Asking a follow up question",
   "id": "84aca14b-ed89-4c80-8b3a-f1c34cb11096"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from utils import llama32repi #helper function for the follow-up question\n",
    "\n",
    "new_question = \"is there banana in the fridge? where?\"\n",
    "messages = [\n",
    "  {\"role\": \"user\", \"content\": [\n",
    "      {\"type\": \"text\", \"text\": question},\n",
    "      {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpg;base64,{base64_image}\"}}\n",
    "  ]},\n",
    "  {\"role\": \"assistant\", \"content\": result},\n",
    "  {\"role\": \"user\", \"content\": new_question}\n",
    "]\n",
    "new_result = llama32(messages)\n",
    "print(new_result)"
   ],
   "id": "fd0259a2-4312-4be0-9352-d2ec4d0ae7eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#equivalently\n",
    "new_result = llama32repi(question, f\"data:image/jpg;base64,{base64_image}\", result, new_question)\n",
    "print(new_result) "
   ],
   "id": "c189e7c0a6a29a87"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It can be used like an interior design assistant, a math grader...etc\n",
    "```python \n",
    "disp_image(\"images/math_hw3.jpg\")\n",
    "prompt = (\"Check carefully each answer in a kid's math homework, first \"\n",
    "          \"do the calculation, then compare the result with the kid's \"\n",
    "          \"answer, mark correct or incorrect for each answer, and finally\"\n",
    "          \" return a total score based on all the problems answered.\")\n",
    "base64_image = encode_image(\"images/math_hw3.jpg\")\n",
    "result = llama32pi(prompt, f\"data:image/jpg;base64,{base64_image}\")\n",
    "print(result)\n",
    "```"
   ],
   "id": "5f5af7e4-31cf-44b3-a4db-d693c2c74c75"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tool calling with image and follow-up response",
   "id": "11ffe21a-79e0-4132-a938-b75dcf0f0966"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "disp_image(\"images/golden_gate.png\")",
   "id": "926d6154-001a-4921-a7d3-4553b0cadc63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "question = (\"Where is the location of the place shown in the picture?\")\n",
    "base64_image = encode_image(\"images/golden_gate.png\")\n",
    "result = llama32pi(question, f\"data:image/png;base64,{base64_image}\")\n",
    "print(result)"
   ],
   "id": "8ead1d85-944d-45f3-9a65-e5d75a46c207"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "weather_question = (\"What is the current weather in the location \"\n",
    "                 \"mentioned in the text below: \\n\"  f\"{result}\")"
   ],
   "id": "1124a89c-f8b1-4752-8f06-5d8d1fd71caa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now()\n",
    "formatted_date = current_date.strftime(\"%d %B %Y\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\":  f\"\"\"\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: {formatted_date}\n",
    "\"\"\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": weather_question}\n",
    "  ]\n",
    "print(llama32(messages)) #it may answer with the function calling for later using it\n",
    "#manually by the user (or directly with the response from the tool)"
   ],
   "id": "cddf2706-4c17-4d6c-a15a-1306d00d43e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
